{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13744746,"sourceType":"datasetVersion","datasetId":8745777}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom skimage.feature import hog\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, accuracy_score\nimport time\n\n# --- 1. Define Paths ---\nbase_path = \"/kaggle/input/animal-ds/\"\ntrain_path = os.path.join(base_path, \"train\")\ntest_path = os.path.join(base_path, \"test\")\nimage_size = (64, 64)\n\n# --- 2. Helper function to load data (now handles different cat folder names) ---\ndef load_images_from_folder(folder_path, cat_folder_name=\"cats\"):\n    data = []\n    labels = []\n    # Load Cats (label 0)\n    cat_folder = os.path.join(folder_path, cat_folder_name) # Use the provided name\n    for img_name in os.listdir(cat_folder):\n        try:\n            img_path = os.path.join(cat_folder, img_name)\n            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n            img_resized = cv2.resize(img, image_size)\n            data.append(img_resized)\n            labels.append(0) # 0 for Cat\n        except Exception as e:\n            print(f\"Error loading {img_path}: {e}\")\n\n    # Load Dogs (label 1) - assuming 'dogs' is the same name in both\n    dog_folder = os.path.join(folder_path, \"dogs\")\n    for img_name in os.listdir(dog_folder):\n        try:\n            img_path = os.path.join(dog_folder, img_name)\n            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n            img_resized = cv2.resize(img, image_size)\n            data.append(img_resized)\n            labels.append(1) # 1 for Dog\n        except Exception as e:\n            print(f\"Error loading {img_path}: {e}\")\n            \n    return np.array(data), np.array(labels)\n\n# --- 3. Load Training and Test Data ---\nprint(\"Loading TRAINING images (using 'cats')...\")\n# Use \"cats\" for the train path\nX_train_img, y_train = load_images_from_folder(train_path, cat_folder_name=\"cats\") \nprint(f\"Training data shape: {X_train_img.shape}\")\n\nprint(\"Loading TEST images (using 'cat_s')...\")\n# Use \"cat_s\" for the test path\nX_test_img, y_test = load_images_from_folder(test_path, cat_folder_name=\"cat_s\") \nprint(f\"Test data shape: {X_test_img.shape}\")\n\n# --- 4. Manual Feature Extraction (HOG) ---\nprint(\"Extracting HOG features for TRAINING data...\")\nhog_features_train = []\nfor image in X_train_img:\n    features = hog(image, pixels_per_cell=(8, 8),\n                   cells_per_block=(2, 2), visualize=False)\n    hog_features_train.append(features)\nhog_features_train = np.array(hog_features_train)\n\nprint(\"Extracting HOG features for TEST data...\")\nhog_features_test = []\nfor image in X_test_img:\n    features = hog(image, pixels_per_cell=(8, 8),\n                   cells_per_block=(2, 2), visualize=False)\n    hog_features_test.append(features)\nhog_features_test = np.array(hog_features_test)\n\n# --- 5. Train Traditional ML Model (SVM) ---\nprint(f\"Training SVM on {len(hog_features_train)} samples...\")\nstart_time = time.time()\nmodel_svm = SVC(kernel='linear', C=1.0)\nmodel_svm.fit(hog_features_train, y_train)\nend_time = time.time()\nprint(f\"SVM training finished in {end_time - start_time:.2f} seconds.\")\n\n# --- 6. Evaluate the Traditional ML Model ---\nprint(\"\\n--- Traditional ML (SVM + HOG) Results ---\")\npredictions = model_svm.predict(hog_features_test)\naccuracy = accuracy_score(y_test, predictions)\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\nprint(classification_report(y_test, predictions, target_names=['Cat', 'Dog']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T17:55:38.230544Z","iopub.execute_input":"2025-11-15T17:55:38.231311Z","iopub.status.idle":"2025-11-15T17:55:44.598892Z","shell.execute_reply.started":"2025-11-15T17:55:38.231283Z","shell.execute_reply":"2025-11-15T17:55:44.598201Z"}},"outputs":[{"name":"stdout","text":"Loading TRAINING images (using 'cats')...\nTraining data shape: (555, 64, 64)\nLoading TEST images (using 'cat_s')...\nTest data shape: (138, 64, 64)\nExtracting HOG features for TRAINING data...\nExtracting HOG features for TEST data...\nTraining SVM on 555 samples...\nSVM training finished in 0.21 seconds.\n\n--- Traditional ML (SVM + HOG) Results ---\nAccuracy: 65.94%\n              precision    recall  f1-score   support\n\n         Cat       0.65      0.70      0.67        69\n         Dog       0.67      0.62      0.65        69\n\n    accuracy                           0.66       138\n   macro avg       0.66      0.66      0.66       138\nweighted avg       0.66      0.66      0.66       138\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"pip install protobuf==3.20.3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T18:03:29.269093Z","iopub.execute_input":"2025-11-15T18:03:29.270391Z","iopub.status.idle":"2025-11-15T18:06:51.494259Z","shell.execute_reply.started":"2025-11-15T18:03:29.270361Z","shell.execute_reply":"2025-11-15T18:06:51.493217Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7b4b46ed61d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/protobuf/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7b4b462ce710>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/protobuf/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7b4b46457cd0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/protobuf/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7b4b4633d4d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/protobuf/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7b4b4634bb50>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/protobuf/\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement protobuf==3.20.3 (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for protobuf==3.20.3\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom sklearn.metrics import classification_report, accuracy_score\nimport time\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\n\n# --- 1. Define Paths ---\nbase_path = \"/kaggle/input/animal-ds/\"\ntrain_path = os.path.join(base_path, \"train\")\ntest_path = os.path.join(base_path, \"test\")\nimage_size = (64, 64)\n\n# --- 2. Helper function to load data (now handles different cat folder names) ---\ndef load_images_for_cnn(folder_path, cat_folder_name=\"cats\"):\n    data = []\n    labels = []\n    # Load Cats (label 0)\n    cat_folder = os.path.join(folder_path, cat_folder_name) # Use the provided name\n    for img_name in os.listdir(cat_folder):\n        try:\n            img_path = os.path.join(cat_folder, img_name)\n            img = cv2.imread(img_path, cv2.IMREAD_COLOR) \n            img_resized = cv2.resize(img, image_size)\n            data.append(img_resized)\n            labels.append(0) # 0 for Cat\n        except Exception as e:\n            print(f\"Error loading {img_path}: {e}\")\n\n    # Load Dogs (label 1)\n    dog_folder = os.path.join(folder_path, \"dogs\")\n    for img_name in os.listdir(dog_folder):\n        try:\n            img_path = os.path.join(dog_folder, img_name)\n            img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n            img_resized = cv2.resize(img, image_size)\n            data.append(img_resized)\n            labels.append(1) # 1 for Dog\n        except Exception as e:\n            print(f\"Error loading {img_path}: {e}\")\n            \n    data_np = np.array(data).astype('float32') / 255.0\n    labels_np = np.array(labels)\n    return data_np, labels_np\n\n# --- 3. Load Training and Test Data ---\nprint(\"Loading TRAINING images for CNN (using 'cats')...\")\n# Use \"cats\" for the train path\nX_train_cnn, y_train_cnn = load_images_for_cnn(train_path, cat_folder_name=\"cats\")\nprint(f\"Training data shape: {X_train_cnn.shape}\")\n\nprint(\"Loading TEST images for CNN (using 'cat_s')...\")\n# Use \"cat_s\" for the test path\nX_test_cnn, y_test_cnn = load_images_for_cnn(test_path, cat_folder_name=\"cat_s\")\nprint(f\"Test data shape: {X_test_cnn.shape}\")\n\n# --- 4. Build the Deep Learning Model (CNN) ---\nprint(\"Building CNN model...\")\nmodel_cnn = models.Sequential()\nmodel_cnn.add(layers.Input(shape=(64, 64, 3)))\nmodel_cnn.add(layers.Conv2D(32, (3, 3), activation='relu'))\nmodel_cnn.add(layers.MaxPooling2D((2, 2)))\nmodel_cnn.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel_cnn.add(layers.MaxPooling2D((2, 2)))\nmodel_cnn.add(layers.Flatten())\nmodel_cnn.add(layers.Dense(64, activation='relu'))\nmodel_cnn.add(layers.Dense(1, activation='sigmoid')) \n\nmodel_cnn.compile(optimizer='adam',\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\nmodel_cnn.summary()\n\n# --- 5. Train the Deep Learning Model ---\nprint(\"Training CNN model...\")\nstart_time = time.time()\nmodel_cnn.fit(X_train_cnn, y_train_cnn, epochs=10, \n              validation_data=(X_test_cnn, y_test_cnn))\nend_time = time.time()\nprint(f\"CNN training finished in {end_time - start_time:.2f} seconds.\")\n\n# --- 6. Evaluate the Deep Learning Model ---\nprint(\"\\n--- Deep Learning (CNN) Results ---\")\ntest_loss, test_acc = model_cnn.evaluate(X_test_cnn, y_test_cnn)\nprint(f\"Accuracy: {test_acc * 100:.2f}%\")\n\npredictions_prob = model_cnn.predict(X_test_cnn)\npredictions_cnn = (predictions_prob > 0.5).astype(int)\nprint(classification_report(y_test_cnn, predictions_cnn, target_names=['Cat', 'Dog']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T18:08:40.841032Z","iopub.execute_input":"2025-11-15T18:08:40.841537Z","iopub.status.idle":"2025-11-15T18:08:53.309253Z","shell.execute_reply.started":"2025-11-15T18:08:40.841497Z","shell.execute_reply":"2025-11-15T18:08:53.308321Z"}},"outputs":[{"name":"stdout","text":"Loading TRAINING images for CNN (using 'cats')...\nTraining data shape: (555, 64, 64, 3)\nLoading TEST images for CNN (using 'cat_s')...\nTest data shape: (138, 64, 64, 3)\nBuilding CNN model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m802,880\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">802,880</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m822,337\u001b[0m (3.14 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">822,337</span> (3.14 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m822,337\u001b[0m (3.14 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">822,337</span> (3.14 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Training CNN model...\nEpoch 1/10\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.4857 - loss: 0.8432 - val_accuracy: 0.4928 - val_loss: 0.6922\nEpoch 2/10\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5006 - loss: 0.6939 - val_accuracy: 0.5000 - val_loss: 0.6899\nEpoch 3/10\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5966 - loss: 0.6776 - val_accuracy: 0.5072 - val_loss: 0.6892\nEpoch 4/10\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5653 - loss: 0.6863 - val_accuracy: 0.5797 - val_loss: 0.6818\nEpoch 5/10\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7344 - loss: 0.6186 - val_accuracy: 0.6304 - val_loss: 0.6610\nEpoch 6/10\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7575 - loss: 0.5379 - val_accuracy: 0.6014 - val_loss: 0.6917\nEpoch 7/10\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7937 - loss: 0.4617 - val_accuracy: 0.6159 - val_loss: 0.7189\nEpoch 8/10\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8441 - loss: 0.3933 - val_accuracy: 0.6377 - val_loss: 0.7248\nEpoch 9/10\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9109 - loss: 0.2790 - val_accuracy: 0.6232 - val_loss: 0.7245\nEpoch 10/10\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9170 - loss: 0.2645 - val_accuracy: 0.5725 - val_loss: 0.7680\nCNN training finished in 5.98 seconds.\n\n--- Deep Learning (CNN) Results ---\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4864 - loss: 0.8582 \nAccuracy: 57.25%\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n              precision    recall  f1-score   support\n\n         Cat       0.61      0.41      0.49        69\n         Dog       0.55      0.74      0.63        69\n\n    accuracy                           0.57       138\n   macro avg       0.58      0.57      0.56       138\nweighted avg       0.58      0.57      0.56       138\n\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"!ls /kaggle/input/animal-ds/train/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T17:49:00.361065Z","iopub.execute_input":"2025-11-15T17:49:00.361429Z","iopub.status.idle":"2025-11-15T17:49:00.492095Z","shell.execute_reply.started":"2025-11-15T17:49:00.361405Z","shell.execute_reply":"2025-11-15T17:49:00.491206Z"}},"outputs":[{"name":"stdout","text":"cats  dogs\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"\nbase_path = \"/kaggle/input/animal-ds/\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T16:19:45.693607Z","iopub.execute_input":"2025-11-15T16:19:45.694379Z","iopub.status.idle":"2025-11-15T16:19:45.699142Z","shell.execute_reply.started":"2025-11-15T16:19:45.694344Z","shell.execute_reply":"2025-11-15T16:19:45.697934Z"}},"outputs":[],"execution_count":19}]}